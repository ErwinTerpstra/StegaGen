{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52220c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import nltk\n",
    "import evaluate\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf2aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA on NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Determine what device to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    device_name = torch.cuda.get_device_name(device)\n",
    "\n",
    "    print(f'CUDA on {device_name}')\n",
    "else:\n",
    "    print(f'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd88ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "\n",
    "SECRET_LENGTH = 16\n",
    "TOKENS_PER_BIT = 1\n",
    "SKIPPED_OUTPUT_TOKENS = 4   \t\t\t# Number of initial output tokens to skip (seem to be constant for SmolLM)\n",
    "PREFIX_LENGTH = 0\t\t\t\t\t\t# Number of tokens in which the secret is encoded before the input prompt. 0 to disable\n",
    "INJECT_SECRET_IN_SYSTEM_PROMPT = False \t# Whether to insert the secret as binary text in the system prompt\n",
    "\n",
    "SHIFT_EMBEDS = False\t\t\t\t\t# A debug hack to trivially encode tokens by shifting embedding bits. Useful to test decoder\n",
    "MASK_TOKENS = True\t\t\t\t\t\t# Whether to mask a subset of tokens basd on the encoded secret bit. A simple form of encoding\n",
    "\n",
    "STEGO_LENGTH = SECRET_LENGTH * TOKENS_PER_BIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9584927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup previous run\n",
    "# This allows rerunning the entire notebook without memory leaks\n",
    "\n",
    "import gc\n",
    "\n",
    "# Delete models, clean up memory\n",
    "\n",
    "if 'generator_tokenizer' in globals():\n",
    "    del generator_tokenizer\n",
    "    \n",
    "if 'decoder_tokenizer' in globals():\n",
    "    del decoder_tokenizer\n",
    "\n",
    "if 'generator' in globals():\n",
    "    del generator\n",
    "    \n",
    "if 'decoder' in globals():\n",
    "    del decoder\n",
    "    \n",
    "if 'semantic_anchor' in globals():\n",
    "    del semantic_anchor\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch._C._cuda_clearCublasWorkspaces()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef47b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.0 MB; Reserved: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Check if everything's cleaned\n",
    "allocated = torch.cuda.memory_allocated() / (1024 * 1024)\n",
    "reserved = torch.cuda.memory_reserved() / (1024 * 1024)\n",
    "\n",
    "print(f'Allocated: {allocated:.1f} MB; Reserved: {reserved:.1f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbad1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StegoEmbeddingDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size=768, output_size=16, pool_size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "        config = BertConfig(\n",
    "            hidden_size=hidden_size,\n",
    "            num_hidden_layers=4,\n",
    "            num_attention_heads=8,\n",
    "            intermediate_size=16 * hidden_size\n",
    "        )\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        # Token-wise binary classification head\n",
    "        # NOTE: 1 layer seems to work fine for now\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * pool_size, 1),\n",
    "            # Note: Sigmoid() seems to strongly decrease decoder effectiveness?\n",
    "            # nn.GELU(),\n",
    "            # nn.Linear(256, 128),\n",
    "            # nn.GELU(),\n",
    "            # nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs_embeds, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        inputs_embeds: (B, N, D)\n",
    "        attention_mask: (B, N) optional\n",
    "        labels: (B, N) optional\n",
    "        \"\"\"\n",
    "\n",
    "        # Run input embeddings through BERT model\n",
    "        outputs = self.bert(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state # (B, N, D)\n",
    "\n",
    "        # Reshape embeddings per token to stack all embeddings for a bit pool\n",
    "        assert hidden_states.shape[1] == self.output_size * self.pool_size, f'Input tokens size error: {hidden_states.shape[1]}. Expected: {self.output_size * self.pool_size}'\n",
    "        assert hidden_states.shape[2] == self.hidden_size, f' Input embedding size error: {hidden_states.shape[2]}. Expected: {self.hidden_size}'\n",
    "        classifier_input = hidden_states.reshape(-1, self.output_size, self.pool_size * self.hidden_size)  # (B, T, P * D)\n",
    "        \n",
    "        # Perform classification to get logits for each bit\n",
    "        logits = self.classifier(classifier_input)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fn(logits.squeeze(-1), labels.float())\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3e9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SecretPrefixEncoder(nn.Module):\n",
    "    def __init__(self, secret_length: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.secret_length = secret_length\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(1, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, bits: torch.Tensor):\n",
    "        \"\"\"\n",
    "        bits: [ B, S ] in {0,1}\n",
    "        returns: [ B, S, D ]\n",
    "        \"\"\"\n",
    "        emb = self.projection(bits.reshape(-1, self.secret_length, 1).float())\n",
    "        return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a15a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator embedding dimensions: 576, vocabulary size: 49152\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "\n",
    "#GENERATOR_MODEL = \"Qwen/Qwen3-0.6B\"\n",
    "#GENERATOR_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#GENERATOR_MODEL = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "GENERATOR_MODEL = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(GENERATOR_MODEL)\n",
    "#decoder_tokenizer = T5Tokenizer.from_pretrained(DECODER_MODEL).to(device)\n",
    "\n",
    "generator = AutoModelForCausalLM.from_pretrained(GENERATOR_MODEL).to(device)\n",
    "decoder = StegoEmbeddingDecoder(hidden_size=generator.config.hidden_size, output_size=SECRET_LENGTH, pool_size=TOKENS_PER_BIT).to(device)\n",
    "\n",
    "if PREFIX_LENGTH > 0:\n",
    "\tprefix_encoder = SecretPrefixEncoder(secret_length=SECRET_LENGTH, hidden_size=generator.config.hidden_size).to(device)\n",
    "\n",
    "#semantic_anchor = AutoModelForCausalLM.from_pretrained(GENERATOR_MODEL).to(device)\n",
    "\n",
    "# Freeze base model\n",
    "#for p in semantic_anchor.parameters():\n",
    "#    p.requires_grad = False\n",
    "\n",
    "generator.train()\n",
    "decoder.train()\n",
    "#semantic_anchor.eval()\n",
    "\n",
    "embedding_size = generator.config.hidden_size\n",
    "vocab_size = generator.config.vocab_size\n",
    "print(f'Generator embedding dimensions: {embedding_size}, vocabulary size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db77fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_secret():\n",
    "    return torch.randint(0, 2, (1, SECRET_LENGTH))   # [ B, N ]\n",
    "\n",
    "def bits_to_str(bits, sep=''):\n",
    "    return sep.join(str(b) for b in bits.tolist())\n",
    "\n",
    "def build_generator_prompt(carrier, secret_bits):\n",
    "\n",
    "    messages = [ ]\n",
    "\n",
    "    if INJECT_SECRET_IN_SYSTEM_PROMPT:\n",
    "        messages.append(\n",
    "            {'role': 'system', 'content': f'You are a helpful assistant who always encodes these bits in their answer: {bits_to_str(secret_bits.flatten(), \" \")}. '}\n",
    "        )\n",
    "\n",
    "    messages.append({'role': 'user', 'content': carrier })\n",
    "\n",
    "    return generator_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "def generate_input_embeddings(input_ids, secret_bits = None):\n",
    "    # Token embeddings based on input tokens\n",
    "    token_embeds = generator.get_input_embeddings()(input_ids) # (B, T, D)\n",
    "\n",
    "    if PREFIX_LENGTH == 0 or secret_bits is None:\n",
    "        return token_embeds\n",
    "    \n",
    "    # Prefix embeddings based on secret bits\n",
    "    prefix_embeds = prefix_encoder(secret_bits)\n",
    "\n",
    "    # Concatenate prefix and token embeddings\n",
    "    input_embeds = torch.cat([prefix_embeds, token_embeds], dim=1)  # (B, T+P, D)\n",
    "    \n",
    "    return input_embeds\n",
    "\n",
    "def mask_indices(bit):\n",
    "    start = 0 if bit.item() == 0 else vocab_size // 2\n",
    "    end = vocab_size if bit.item() == 1 else vocab_size // 2\n",
    "\n",
    "    #return range(start, end)\n",
    "    return range(bit.item(), vocab_size, 2)\n",
    "\n",
    "@torch.no_grad()\n",
    "def generator_forward(secret_bit = None, temperature=1.0, **kwargs):\n",
    "    out = generator(\n",
    "        **kwargs,\n",
    "        return_dict=True,\n",
    "        use_cache=True,\n",
    "        eos_token_id=None, # prevent early stop\n",
    "    )\n",
    "\n",
    "    logits = out.logits[:, -1, :]   # [B, V]\n",
    "\n",
    "    if MASK_TOKENS and secret_bit is not None:\n",
    "        # Create a mask to mask out subsets of tokens\n",
    "        logit_mask = torch.full((vocab_size, ), True)\n",
    "        \n",
    "        # bit = 0: mask even tokens\n",
    "        # bit = 1: mask odd tokens\n",
    "        masked_indices = list(mask_indices(secret_bit))\n",
    "        logit_mask[masked_indices] = False\n",
    "\n",
    "        # Mask out tokens we don't allow\n",
    "        logits[:, ~logit_mask] = -math.inf\n",
    "\n",
    "    probs = torch.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "    return logits, probs, out.past_key_values\n",
    "\n",
    "def soft_embeddings(token_probs):\n",
    "    embed_matrix = generator.get_input_embeddings().weight  # [V, d]\n",
    "    return token_probs @ embed_matrix\n",
    "\n",
    "@torch.no_grad()\n",
    "def anchor_forward(anchor, inputs) -> torch.Tensor:\n",
    "    outputs = anchor(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        return_dict=True\n",
    "    )\n",
    "    logits = outputs.logits[:, :STEGO_LENGTH, :]\n",
    "    return logits\n",
    "\n",
    "def kl_semantic_loss(stego_logits, base_logits):\n",
    "    p = F.log_softmax(stego_logits, dim=-1)\n",
    "    q = F.softmax(base_logits, dim=-1)\n",
    "\n",
    "    # Masked?\n",
    "    # kl = F.kl_div(log_p, q, reduction=\"none\")  # [B, T, V]\n",
    "    # kl = kl.sum(dim=-1)                        # [B, T]\n",
    "\n",
    "    # # Mask padding tokens\n",
    "    # kl = kl * attention_mask\n",
    "\n",
    "    # return kl.sum() / attention_mask.sum()\n",
    "\n",
    "    return F.kl_div(p, q, reduction=\"batchmean\")\n",
    "\n",
    "def decoder_forward(soft_embeds, secret_bits):\n",
    "    out = decoder(inputs_embeds=soft_embeds, labels=secret_bits)\n",
    "\n",
    "    return out['loss']\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode(carrier, secret_bits):\n",
    "    prompt = build_generator_prompt(carrier, secret_bits)\n",
    "    inputs = generator_tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    input_embeddings = generate_input_embeddings(inputs.input_ids.to(device), secret_bits)\n",
    "    past_kv = None\n",
    "\n",
    "    # Generate N tokens, store ids for each token\n",
    "    selected_tokens = [ ]\n",
    "    for t in range(STEGO_LENGTH + SKIPPED_OUTPUT_TOKENS):   \n",
    "        stego_logits, token_probs, past_kv = generator_forward(\n",
    "            secret_bit = secret_bits[0, t - SKIPPED_OUTPUT_TOKENS] if t >= SKIPPED_OUTPUT_TOKENS else None,\n",
    "            inputs_embeds=input_embeddings,\n",
    "            past_key_values=past_kv\n",
    "        )\n",
    "\n",
    "        # Select the top probability token\n",
    "        predictions = torch.argmax(token_probs, dim=-1)\n",
    "\n",
    "        # Convert the token to 'hard' embeddings again for the next iteration\n",
    "        embedding_layer = generator.get_input_embeddings()\n",
    "        input_embeddings = embedding_layer(predictions).unsqueeze(1) # (B, 1, D)\n",
    "        \n",
    "        if t >= SKIPPED_OUTPUT_TOKENS:\n",
    "            selected_tokens.append(predictions[0])\n",
    "\n",
    "    return generator_tokenizer.decode(selected_tokens, skip_special_tokens=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def decode(stego_text):\n",
    "    encoded_token_ids = generator_tokenizer(stego_text, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Ensure correct length, discard extra tokens and pad if too short\n",
    "    encoded_token_ids = encoded_token_ids[:, :STEGO_LENGTH]\n",
    "    encoded_token_ids = F.pad(encoded_token_ids, (0, STEGO_LENGTH - encoded_token_ids.shape[1]), value=generator_tokenizer.pad_token_id)\n",
    "\n",
    "    # Encoder embedding matrix\n",
    "    embedding_layer = generator.get_input_embeddings()\n",
    "\n",
    "    # (B, N, D)\n",
    "    encoded_embeds = embedding_layer(encoded_token_ids.to(device))\n",
    "\n",
    "    #attention_mask = torch.ones(encoded_embeds.shape[:2])\n",
    "\n",
    "    out = decoder(\n",
    "        inputs_embeds=encoded_embeds\n",
    "        #attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "    logits = out[\"logits\"]      # (B, N, 1)\n",
    "    preds = (logits.squeeze(-1) > 0).long()\n",
    "    \n",
    "    return preds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da514610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a short paragraph explaining how neural networks learn.<|im_end|>\n",
      "\n",
      "----------------\n",
      "A neural network is an intelligent machine capable by complex patterns in data which are used\n"
     ]
    }
   ],
   "source": [
    "# Test prompt generation and generation inference\n",
    "\n",
    "carrier = \"Write a short paragraph explaining how neural networks learn.\"\n",
    "secret = generate_secret().to(device)\n",
    "\n",
    "print(build_generator_prompt(carrier, secret))\n",
    "print('----------------')\n",
    "print(encode(carrier, secret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3090283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | L_sem: 0.000 | L_rec: 0.693\n",
      "Secret:  1001010000001011\n",
      "Decoded: 0001000000000000\n",
      "Stego:   Neural networks, a type-1 generalization model in computer science named after the\n",
      "\n",
      "Step 1 | L_sem: 0.000 | L_rec: 0.869\n",
      "Secret:  1001111110110001\n",
      "Decoded: 0001101100101001\n",
      "Stego:   Neural networks, like any other machine learning model, learns by adjusting weights and\n",
      "\n",
      "Step 2 | L_sem: 0.000 | L_rec: 0.366\n",
      "Secret:  0010100100100010\n",
      "Decoded: 0001110110111101\n",
      "Stego:   I've heard a number people say that a lot, especially in recent months when\n",
      "\n",
      "Step 3 | L_sem: 0.000 | L_rec: 0.577\n",
      "Secret:  0100011000011101\n",
      "Decoded: 1011110111011001\n",
      "Stego:   I'm here for a simple explanation on understanding a fundamental process of artificial Intelligence,\n",
      "\n",
      "Step 4 | L_sem: 0.000 | L_rec: 0.625\n",
      "Secret:  0011100111100010\n",
      "Decoded: 1001001101011010\n",
      "Stego:   I've heard of neural networks - they're like computers with a mind. They\n",
      "\n",
      "Step 5 | L_sem: 0.000 | L_rec: 0.677\n",
      "Secret:  0010001110011010\n",
      "Decoded: 0001110011111111\n",
      "Stego:   I've heard a lot about neural network learning! It's like a brain in\n",
      "\n",
      "Step 6 | L_sem: 0.000 | L_rec: 0.272\n",
      "Secret:  0111101010100011\n",
      "Decoded: 0001011011010101\n",
      "Stego:   I'm glad you're here to learn. Nearest-to-home is\n",
      "\n",
      "Step 7 | L_sem: 0.000 | L_rec: 0.667\n",
      "Secret:  1010100010101111\n",
      "Decoded: 1000110010101101\n",
      "Stego:   Neural network learn through a combination method of supervised and reinforcement learning. Here's\n",
      "\n",
      "Step 8 | L_sem: 0.000 | L_rec: 0.286\n",
      "Secret:  1001111101110011\n",
      "Decoded: 1001101010010001\n",
      "Stego:   Neural networks, like any other machine-learnED, learn by processing and\n",
      "\n",
      "Step 9 | L_sem: 0.000 | L_rec: 1.107\n",
      "Secret:  1111100111001011\n",
      "Decoded: 1001100110001011\n",
      "Stego:   Ne neural network learning is a fundamental process that enables a computer to recognize complex and\n",
      "\n",
      "Step 10 | L_sem: 0.000 | L_rec: 0.590\n",
      "Secret:  1010011100000101\n",
      "Decoded: 1010000000001111\n",
      "Stego:   Neural network learn by iterating through a hierarchical model architecture where the input is\n",
      "\n",
      "Step 11 | L_sem: 0.000 | L_rec: 0.250\n",
      "Secret:  1010100011011000\n",
      "Decoded: 1010001111011111\n",
      "Stego:   Neural network learn through a combination method of training which includes the following steps in\n",
      "\n",
      "Step 12 | L_sem: 0.000 | L_rec: 0.332\n",
      "Secret:  0001000110001110\n",
      "Decoded: 0011001011011110\n",
      "Stego:   I've been trained on a vast amount of datasets from various domains, and I\n",
      "\n",
      "Step 13 | L_sem: 0.000 | L_rec: 0.243\n",
      "Secret:  0011000001101010\n",
      "Decoded: 0001000011101100\n",
      "Stego:   I've heard of a lot about these amazing algorithms, especially the ones that learn\n",
      "\n",
      "Step 14 | L_sem: 0.000 | L_rec: 0.393\n",
      "Secret:  0001101100101100\n",
      "Decoded: 0001000011101011\n",
      "Stego:   I've been trained to learn through the application method, which is the core concept\n",
      "\n",
      "Step 15 | L_sem: 0.000 | L_rec: 0.431\n",
      "Secret:  1001010010000100\n",
      "Decoded: 1011010010000011\n",
      "Stego:   Neural networks, a type-1 of computer networks with a single hidden unit\n",
      "\n",
      "Step 16 | L_sem: 0.000 | L_rec: 0.482\n",
      "Secret:  1111011001111110\n",
      "Decoded: 1111000000001010\n",
      "Stego:   Ne neural network learning involves training the model on the data to minimize the error in\n",
      "\n",
      "Step 17 | L_sem: 0.000 | L_rec: 0.096\n",
      "Secret:  0110100001010000\n",
      "Decoded: 0000000001110100\n",
      "Stego:   I'm glad I could assist with this! Neural networks, also known as multi\n",
      "\n",
      "Step 18 | L_sem: 0.000 | L_rec: 0.205\n",
      "Secret:  1110001000010001\n",
      "Decoded: 1110000111011011\n",
      "Stego:   Ne neural network learn by using the concept called supervised or unsupervised Learning in supervised learning\n",
      "\n",
      "Step 19 | L_sem: 0.000 | L_rec: 0.205\n",
      "Secret:  1011001100000000\n",
      "Decoded: 1011101100000100\n",
      "Stego:   Neural network learning refers a process of developing a model from a dataset by incorporating\n",
      "\n",
      "Step 20 | L_sem: 0.000 | L_rec: 0.108\n",
      "Secret:  0000001100000100\n",
      "Decoded: 0000001000000000\n",
      "Stego:   I've been working on a neural network for a while now - the model I\n",
      "\n",
      "Step 21 | L_sem: 0.000 | L_rec: 0.270\n",
      "Secret:  1110101110110010\n",
      "Decoded: 1110001111000011\n",
      "Stego:   Ne neural network learn through a process of iterative refinement and optimization in a neural networks\n",
      "\n",
      "Step 22 | L_sem: 0.000 | L_rec: 0.410\n",
      "Secret:  1000010011011100\n",
      "Decoded: 1010000111010100\n",
      "Stego:   Neural networks learn by iteratively adjusting the parameters or \"weights\" in a\n",
      "\n",
      "Step 23 | L_sem: 0.000 | L_rec: 0.097\n",
      "Secret:  1010100000000010\n",
      "Decoded: 1010001111010110\n",
      "Stego:   Neural network learn through a combination method called supervised or reinforcement-learning. This\n",
      "\n",
      "Step 24 | L_sem: 0.000 | L_rec: 0.114\n",
      "Secret:  0001010110111101\n",
      "Decoded: 0000111110101001\n",
      "Stego:   I've been trained on the dataset, and I can provide you an in depth\n",
      "\n",
      "Step 25 | L_sem: 0.000 | L_rec: 0.032\n",
      "Secret:  0010000011011001\n",
      "Decoded: 0000100011011101\n",
      "Stego:   I've heard a lot about these amazing algorithms, especially the one I mentioned,\n",
      "\n",
      "Step 26 | L_sem: 0.000 | L_rec: 0.109\n",
      "Secret:  0110011101000110\n",
      "Decoded: 0110011111111111\n",
      "Stego:   I'm glad I have the ability to learn. In essence it's the combination\n",
      "\n",
      "Step 27 | L_sem: 0.000 | L_rec: 0.123\n",
      "Secret:  0011010110011000\n",
      "Decoded: 0001011110011000\n",
      "Stego:   I've heard of a neural networks, but I've yet to see a real\n",
      "\n",
      "Step 28 | L_sem: 0.000 | L_rec: 0.053\n",
      "Secret:  0110110001100100\n",
      "Decoded: 0100111111110001\n",
      "Stego:   I'm glad I could help with this! Neural network learn by iteratively updating\n",
      "\n",
      "Step 29 | L_sem: 0.000 | L_rec: 0.591\n",
      "Secret:  1100000000011010\n",
      "Decoded: 1111000111011111\n",
      "Stego:   Ne neural networks learn by using a combination combination or combination of algorithms which is called\n",
      "\n",
      "Step 30 | L_sem: 0.000 | L_rec: 0.120\n",
      "Secret:  1011011010010001\n",
      "Decoded: 1011011110010001\n",
      "Stego:   Neural network learning refers to the development of a model that uses a combination of\n",
      "\n",
      "Step 31 | L_sem: 0.000 | L_rec: 0.102\n",
      "Secret:  1001100000011011\n",
      "Decoded: 1001110010010110\n",
      "Stego:   Neural networks, like all computational models in computer Science, rely on the principles\n",
      "\n",
      "Step 32 | L_sem: 0.000 | L_rec: 0.154\n",
      "Secret:  1100110100101111\n",
      "Decoded: 1100000100101011\n",
      "Stego:   Ne neural networks learn through an interaction between a dataset and a learning algorithm. The\n",
      "\n",
      "Step 33 | L_sem: 0.000 | L_rec: 0.436\n",
      "Secret:  1101011001011010\n",
      "Decoded: 1101101100011010\n",
      "Stego:   Ne neural networks, also referred to as feed fed or deep learning models, learn\n",
      "\n",
      "Step 34 | L_sem: 0.000 | L_rec: 0.256\n",
      "Secret:  1110000110111000\n",
      "Decoded: 1100000110100100\n",
      "Stego:   Ne neural network learn by using a process of iteration and backtracking in a hierarchical\n",
      "\n",
      "Step 35 | L_sem: 0.000 | L_rec: 0.025\n",
      "Secret:  0010111111001011\n",
      "Decoded: 0000110011010001\n",
      "Stego:   I've heard a number of terms related to neural networks (NNs); so\n",
      "\n",
      "Step 36 | L_sem: 0.000 | L_rec: 0.119\n",
      "Secret:  0100011010001010\n",
      "Decoded: 0000000110010010\n",
      "Stego:   I'm here for a simple explanation on how a basic neuron works in the human\n",
      "\n",
      "Step 37 | L_sem: 0.000 | L_rec: 0.259\n",
      "Secret:  0011110011101100\n",
      "Decoded: 0001101100011000\n",
      "Stego:   I've heard of neural network (NERB)-based methods, but I've\n",
      "\n",
      "Step 38 | L_sem: 0.000 | L_rec: 0.128\n",
      "Secret:  1101100001101111\n",
      "Decoded: 1101111101011011\n",
      "Stego:   Ne neural networks, commonly known as CNNs, rely on the principles of machine\n",
      "\n",
      "Step 39 | L_sem: 0.000 | L_rec: 0.027\n",
      "Secret:  0111101010111010\n",
      "Decoded: 0111001111011110\n",
      "Stego:   I'm glad you're here to learn. Nearest to the heart of computer\n",
      "\n",
      "Step 40 | L_sem: 0.000 | L_rec: 0.037\n",
      "Secret:  0011011100111010\n",
      "Decoded: 0001011101111111\n",
      "Stego:   I've heard of a neural network, a fascinating and complex algorithm in machine Learning\n",
      "\n",
      "Step 41 | L_sem: 0.000 | L_rec: 0.259\n",
      "Secret:  1110010011111011\n",
      "Decoded: 1111011111111011\n",
      "Stego:   Ne neural network learn by iteratively updating the parameters of the network in the process\n",
      "\n",
      "Step 42 | L_sem: 0.000 | L_rec: 0.066\n",
      "Secret:  1001101101010111\n",
      "Decoded: 1001111101110110\n",
      "Stego:   Neural networks, like all artificial intelligence models, learn through a process of complex\n",
      "\n",
      "Step 43 | L_sem: 0.000 | L_rec: 0.365\n",
      "Secret:  1111101100111001\n",
      "Decoded: 1101101110111011\n",
      "Stego:   Ne neural network learning is a process of developing a machine learning algorithm by feeding the\n",
      "\n",
      "Step 44 | L_sem: 0.000 | L_rec: 0.311\n",
      "Secret:  1101010101010000\n",
      "Decoded: 1101111101011000\n",
      "Stego:   Ne neural networks, also referred as deep-learn networks, learn by approximating\n",
      "\n",
      "Step 45 | L_sem: 0.000 | L_rec: 0.241\n",
      "Secret:  0100110000011001\n",
      "Decoded: 0100100000011111\n",
      "Stego:   I'm here for help explaining a fundamental concept in computer science: **learning algorithms\n",
      "\n",
      "Step 46 | L_sem: 0.000 | L_rec: 0.040\n",
      "Secret:  0100100010001111\n",
      "Decoded: 0000001000000101\n",
      "Stego:   I'm here for help with your math problems! I've studied the basics of\n",
      "\n",
      "Step 47 | L_sem: 0.000 | L_rec: 0.132\n",
      "Secret:  1000010011000111\n",
      "Decoded: 1000000010000101\n",
      "Stego:   Neural networks learn by iteratively adjusting the parameters or weights in the network to\n",
      "\n",
      "Step 48 | L_sem: 0.000 | L_rec: 0.183\n",
      "Secret:  1100011011011100\n",
      "Decoded: 1100000010010100\n",
      "Stego:   Ne neural networks learn by iterating on the same input, output, or pattern\n",
      "\n",
      "Step 49 | L_sem: 0.000 | L_rec: 0.245\n",
      "Secret:  1010000101111100\n",
      "Decoded: 1000000110010100\n",
      "Stego:   Neural network learn by using a process called back propagation, specifically the concept known\n",
      "\n",
      "Step 50 | L_sem: 0.000 | L_rec: 0.421\n",
      "Secret:  1011101001111000\n",
      "Decoded: 1001101000111000\n",
      "Stego:   Neural network learning is a process where a machine learning algorithm is taught by example\n",
      "\n",
      "Step 51 | L_sem: 0.000 | L_rec: 0.375\n",
      "Secret:  1101100110100110\n",
      "Decoded: 1101000110100001\n",
      "Stego:   Ne neural networks, commonly known as deep learning models, learn by iterating on\n",
      "\n",
      "Step 52 | L_sem: 0.000 | L_rec: 0.017\n",
      "Secret:  0010101110111111\n",
      "Decoded: 0000110110111010\n",
      "Stego:   I've heard a number people refer to neural networks, but what do they actually\n",
      "\n",
      "Step 53 | L_sem: 0.000 | L_rec: 0.029\n",
      "Secret:  0101000101100111\n",
      "Decoded: 0101001111001111\n",
      "Stego:   I'm here to assist with understanding and implementing neural network models in data analysis and\n",
      "\n",
      "Step 54 | L_sem: 0.000 | L_rec: 0.141\n",
      "Secret:  1011000100000001\n",
      "Decoded: 1011100110100001\n",
      "Stego:   Neural network learning refers a fundamental process in computer Science where a computer system is\n",
      "\n",
      "Step 55 | L_sem: 0.000 | L_rec: 0.106\n",
      "Secret:  1001011111101111\n",
      "Decoded: 1001011111101110\n",
      "Stego:   Neural networks, a type of machine learning algorithm inspired by the structure and organization\n",
      "\n",
      "Step 56 | L_sem: 0.000 | L_rec: 0.047\n",
      "Secret:  0011011101010010\n",
      "Decoded: 0001011101110111\n",
      "Stego:   I've heard of a neural network, a complex system of interconnected nodes that learn\n",
      "\n",
      "Step 57 | L_sem: 0.000 | L_rec: 0.085\n",
      "Secret:  0001010010111011\n",
      "Decoded: 0011111010011111\n",
      "Stego:   I've been trained on the dataset provided, which consists of 100\n",
      "\n",
      "Step 58 | L_sem: 0.000 | L_rec: 0.023\n",
      "Secret:  0010011100110101\n",
      "Decoded: 0000011110110111\n",
      "Stego:   I've heard a lot of interesting stories about using neural network models to learn.\n",
      "\n",
      "Step 59 | L_sem: 0.000 | L_rec: 0.281\n",
      "Secret:  1101000100101000\n",
      "Decoded: 1101100100101100\n",
      "Stego:   Ne neural networks, also known as deep networks or neural networks, learn by using\n",
      "\n",
      "Step 60 | L_sem: 0.000 | L_rec: 0.309\n",
      "Secret:  1010001001110111\n",
      "Decoded: 1011001001111111\n",
      "Stego:   Neural network learn by using the combination or layering of layers in the training data\n",
      "\n",
      "Step 61 | L_sem: 0.000 | L_rec: 0.122\n",
      "Secret:  1001100011111000\n",
      "Decoded: 1001111010011000\n",
      "Stego:   Neural networks, like all computational models, rely heavily upon the combination or application\n",
      "\n",
      "Step 62 | L_sem: 0.000 | L_rec: 0.021\n",
      "Secret:  0110001010011011\n",
      "Decoded: 0100001110001101\n",
      "Stego:   I'm glad I have a deep understanding of this fascinating topic. Nearest to\n",
      "\n",
      "Step 63 | L_sem: 0.000 | L_rec: 0.071\n",
      "Secret:  1100111110000010\n",
      "Decoded: 1100110110000110\n",
      "Stego:   Ne neural networks learn through an iterative process of pattern recognition in a dataset. This\n",
      "\n",
      "Step 64 | L_sem: 0.000 | L_rec: 0.081\n",
      "Secret:  0100011111101011\n",
      "Decoded: 0100000111101110\n",
      "Stego:   I'm here for a simple explanation of how neural nets learn. Let's start\n",
      "\n",
      "Step 65 | L_sem: 0.000 | L_rec: 0.073\n",
      "Secret:  1111000100000111\n",
      "Decoded: 1101000100001110\n",
      "Stego:   Ne neural network learning involves a combination of supervised or unsupervised reinforcement learning, and\n",
      "\n",
      "Step 66 | L_sem: 0.000 | L_rec: 0.003\n",
      "Secret:  0001111100011000\n",
      "Decoded: 0000101100010000\n",
      "Stego:   I've been trained to understand the process behind a basic neural network model in a\n",
      "\n",
      "Step 67 | L_sem: 0.000 | L_rec: 0.022\n",
      "Secret:  1111100110110010\n",
      "Decoded: 1101100110110010\n",
      "Stego:   Ne neural network learning is a fundamental process that involves the training model using an input\n",
      "\n",
      "Step 68 | L_sem: 0.000 | L_rec: 0.006\n",
      "Secret:  0110010000001100\n",
      "Decoded: 0100011001101000\n",
      "Stego:   I'm glad I have the opportunity! I'd be happy to explain in a\n",
      "\n",
      "Step 69 | L_sem: 0.000 | L_rec: 0.009\n",
      "Secret:  0011100100100111\n",
      "Decoded: 0101100100100101\n",
      "Stego:   I've heard of neural networks - they are a type computer system that mimics the\n",
      "\n",
      "Step 70 | L_sem: 0.000 | L_rec: 0.036\n",
      "Secret:  1110011001000110\n",
      "Decoded: 1100010101001100\n",
      "Stego:   Ne neural network learn by iterating on a set input-out set mapping (\n",
      "\n",
      "Step 71 | L_sem: 0.000 | L_rec: 0.006\n",
      "Secret:  0110000100110111\n",
      "Decoded: 0000000010110110\n",
      "Stego:   I'm glad I have a human guide for this. Neural networks, like any\n",
      "\n",
      "Step 72 | L_sem: 0.000 | L_rec: 0.259\n",
      "Secret:  1101001001110010\n",
      "Decoded: 1101000011110111\n",
      "Stego:   Ne neural networks, also known simply as CNN, is an ensemble method used for\n",
      "\n",
      "Step 73 | L_sem: 0.000 | L_rec: 0.005\n",
      "Secret:  0010110000011001\n",
      "Decoded: 0000111000000100\n",
      "Stego:   I've heard a number of people say I have a knack for teaching complex\n",
      "\n",
      "Step 74 | L_sem: 0.000 | L_rec: 0.007\n",
      "Secret:  0010110110011011\n",
      "Decoded: 0000111010011011\n",
      "Stego:   I've heard a number of people ask how a computer learns, which is an\n",
      "\n",
      "Step 75 | L_sem: 0.000 | L_rec: 0.006\n",
      "Secret:  1000110110100110\n",
      "Decoded: 1000110110101111\n",
      "Stego:   Neural networks learn through an interaction between the input data (e. g.,\n",
      "\n",
      "Step 76 | L_sem: 0.000 | L_rec: 0.005\n",
      "Secret:  0111000100100101\n",
      "Decoded: 0111010101100110\n",
      "Stego:   I'm glad you asked for a simple example! Neural networks are an essential building\n",
      "\n",
      "Step 77 | L_sem: 0.000 | L_rec: 0.070\n",
      "Secret:  1101001110110000\n",
      "Decoded: 1101000110110100\n",
      "Stego:   Ne neural networks, also known simply, \"networks\", work by using a combination\n",
      "\n",
      "Step 78 | L_sem: 0.000 | L_rec: 0.019\n",
      "Secret:  0001010010001000\n",
      "Decoded: 0001111010000110\n",
      "Stego:   I've been trained on the dataset provided, which contains a mix from various fields\n",
      "\n",
      "Step 79 | L_sem: 0.000 | L_rec: 0.111\n",
      "Secret:  1001000011111010\n",
      "Decoded: 1001001111111010\n",
      "Stego:   Neural networks, a fundamental concept in machine learning, work through a process called\n",
      "\n",
      "Step 80 | L_sem: 0.000 | L_rec: 0.061\n",
      "Secret:  1111110110010100\n",
      "Decoded: 1101111110010100\n",
      "Stego:   Ne neural network learning is an essential topic that involves a deep understanding of various components\n",
      "\n",
      "Step 81 | L_sem: 0.000 | L_rec: 0.010\n",
      "Secret:  0000111101110100\n",
      "Decoded: 0100011001110110\n",
      "Stego:   I've been working closely under the mentorship provided, and the insights and knowledge I\n",
      "\n",
      "Step 82 | L_sem: 0.000 | L_rec: 0.148\n",
      "Secret:  0100000000010011\n",
      "Decoded: 0110010100101010\n",
      "Stego:   I'm here for a role-play where I will help users explore the intricacies\n",
      "\n",
      "Step 83 | L_sem: 0.000 | L_rec: 0.002\n",
      "Secret:  0010000111001110\n",
      "Decoded: 0100010111001010\n",
      "Stego:   I've heard a lot about these incredible algorithms, especially when they're used in\n",
      "\n",
      "Step 84 | L_sem: 0.000 | L_rec: 0.021\n",
      "Secret:  0001110101111010\n",
      "Decoded: 0001100001011110\n",
      "Stego:   I've been trained to understand human concepts in the context of AI development. I\n",
      "\n",
      "Step 85 | L_sem: 0.000 | L_rec: 0.012\n",
      "Secret:  0101111100001100\n",
      "Decoded: 0100000100011100\n",
      "Stego:   I'm here to help you understand how your computer or software learns. In a\n",
      "\n",
      "Step 86 | L_sem: 0.000 | L_rec: 0.062\n",
      "Secret:  1100011110001010\n",
      "Decoded: 1100011110001110\n",
      "Stego:   Ne neural networks learn by iterating through layers in a hierarchical manner until the desired\n",
      "\n",
      "Step 87 | L_sem: 0.000 | L_rec: 0.035\n",
      "Secret:  1111001001101011\n",
      "Decoded: 1101001001101001\n",
      "Stego:   Ne neural network learning involves a process where a machine learning model is taught to process\n",
      "\n",
      "Step 88 | L_sem: 0.000 | L_rec: 0.002\n",
      "Secret:  0100010100111010\n",
      "Decoded: 0100001100111000\n",
      "Stego:   I'm here for a simple summary of a fundamental process that neural networks use for\n",
      "\n",
      "Step 89 | L_sem: 0.000 | L_rec: 0.015\n",
      "Secret:  0001111011101101\n",
      "Decoded: 0000001011000100\n",
      "Stego:   I've been trained to understand the concept of neural network learnings. In simple\n",
      "\n",
      "Step 90 | L_sem: 0.000 | L_rec: 0.004\n",
      "Secret:  1001100110100011\n",
      "Decoded: 1001111110100011\n",
      "Stego:   Neural networks, like all computational systems, learn through a hierarchical model of computation\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m generated_embeds = []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(STEGO_LENGTH + SKIPPED_OUTPUT_TOKENS): \n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     stego_logits, token_probs, past_kv = \u001b[43mgenerator_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43msecret_bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msecret_bits\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mSKIPPED_OUTPUT_TOKENS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mSKIPPED_OUTPUT_TOKENS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msoft_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     soft_embeds = soft_embeddings(token_probs)  \u001b[38;5;66;03m# [ B, D ]\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Only save embeds after the first X tokens\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mgenerator_forward\u001b[39m\u001b[34m(secret_bit, temperature, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerator_forward\u001b[39m(secret_bit = \u001b[38;5;28;01mNone\u001b[39;00m, temperature=\u001b[32m1.0\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     out = \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# prevent early stop\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     logits = out.logits[:, -\u001b[32m1\u001b[39m, :]   \u001b[38;5;66;03m# [B, V]\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m MASK_TOKENS \u001b[38;5;129;01mand\u001b[39;00m secret_bit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Create a mask to mask out subsets of tokens\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:459\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    441\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:395\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    407\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    408\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    409\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:294\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:246\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    245\u001b[39m     cache_kwargs = {\u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin, \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos, \u001b[33m\"\u001b[39m\u001b[33mcache_position\u001b[39m\u001b[33m\"\u001b[39m: cache_position}\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     key_states, value_states = \u001b[43mpast_key_values\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m attention_interface: Callable = eager_attention_forward\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\cache_utils.py:776\u001b[39m, in \u001b[36mCache.update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m     torch.cuda.default_stream(key_states.device).wait_stream(\u001b[38;5;28mself\u001b[39m.prefetch_stream)\n\u001b[32m    774\u001b[39m     \u001b[38;5;28mself\u001b[39m.prefetch(layer_idx + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m keys, values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offloading:\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m.offload(layer_idx, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\erwin\\miniconda3\\envs\\stega\\Lib\\site-packages\\transformers\\cache_utils.py:120\u001b[39m, in \u001b[36mDynamicLayer.update\u001b[39m\u001b[34m(self, key_states, value_states, cache_kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m.lazy_initialization(key_states)\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.keys = torch.cat([\u001b[38;5;28mself\u001b[39m.keys, key_states], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28mself\u001b[39m.values = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys, \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "\n",
    "# Collect all model parameters\n",
    "parameters = [ ]\n",
    "#parameters += list(generator.parameters())\n",
    "parameters += list(decoder.parameters())\n",
    "\n",
    "if PREFIX_LENGTH > 0:\n",
    "    parameters += list(prefix_encoder.parameters())\n",
    "\n",
    "optimizer = torch.optim.AdamW(parameters, lr=3e-5)\n",
    "\n",
    "for step in range(1000):\n",
    "    carrier_prompt = \"Explain how neural networks learn.\"\n",
    "    secret_bits = generate_secret().to(device)\n",
    "\n",
    "    prompt = build_generator_prompt(carrier_prompt, secret_bits)\n",
    "    generator_inputs = generator_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    # Prepare embeddings for first step by adding secret prefix to token embeddings\n",
    "    soft_embeds = generate_input_embeddings(generator_inputs, secret_bits)\n",
    "    past_kv = None\n",
    "\n",
    "    # Generate N tokens, store embeddings for each token\n",
    "    generated_embeds = []\n",
    "    for t in range(STEGO_LENGTH + SKIPPED_OUTPUT_TOKENS): \n",
    "        stego_logits, token_probs, past_kv = generator_forward(\n",
    "            secret_bit = secret_bits[0, t - SKIPPED_OUTPUT_TOKENS] if t >= SKIPPED_OUTPUT_TOKENS else None,\n",
    "            inputs_embeds=soft_embeds,\n",
    "            past_key_values=past_kv\n",
    "        )\n",
    "\n",
    "        soft_embeds = soft_embeddings(token_probs)  # [ B, D ]\n",
    "\n",
    "        # Only save embeds after the first X tokens\n",
    "        if t >= SKIPPED_OUTPUT_TOKENS:\n",
    "            if SHIFT_EMBEDS:\n",
    "                # HACK: Modulate embeddings based on secret bit to test decoder\n",
    "                bit = secret_bits[0, t - SKIPPED_OUTPUT_TOKENS]\n",
    "                shifted_embeds = torch.mul(soft_embeds, bit * 2 - 1)\n",
    "            else:\n",
    "                shifted_embeds = soft_embeds\n",
    "\n",
    "            generated_embeds.append(shifted_embeds)\n",
    "\n",
    "        # Take soft embeds for next step\n",
    "        soft_embeds = soft_embeds.unsqueeze(1)\n",
    "\n",
    "    #print(f'Number of generated embeddings: {len(generated_embeds)}, skipping first {SKIPPED_OUTPUT_TOKENS}...')\n",
    "\n",
    "    # Stack embeddings for each token to [ B, N, D ]\n",
    "    encoder_outputs_embeds = torch.stack(generated_embeds, dim=1).to(device)\n",
    "\n",
    "    #print(f'Encoder outputs embeddings shape: {encoder_outputs_embeds.shape}')\n",
    "\n",
    "    # Calculate recovery loss based on decoding success\n",
    "    recovery_loss = decoder_forward(encoder_outputs_embeds, secret_bits.to(device))\n",
    "\n",
    "    # Calculate semantic loss compared to base model\n",
    "    #base_logits = anchor_forward(semantic_anchor, generator_inputs)\n",
    "    #semantic_loss = kl_semantic_loss(stego_logits, base_logits)\n",
    "    semantic_loss = np.zeros(1)\n",
    "\n",
    "    # Combine loss\n",
    "    loss = recovery_loss\n",
    "    #loss = 1.0 * recovery_loss + 0.0 * semantic_loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if step % 1 == 0:\n",
    "        stego_text = encode(carrier_prompt, secret_bits)\n",
    "        secret_str = bits_to_str(secret_bits.flatten())\n",
    "        decoded_secret_bits = decode(stego_text)\n",
    "        decoded_secret_str = bits_to_str(decoded_secret_bits)\n",
    "\n",
    "        print(f\"Step {step} | L_sem: {semantic_loss.item():.3f} | L_rec: {recovery_loss.item():.3f}\")\n",
    "        print(f'Secret:  {secret_str}')\n",
    "        print(f'Decoded: {decoded_secret_str}')\n",
    "        print(f'Stego:   {stego_text}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb69447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stego text:\n",
      "Here are some delicious Italian pasta bolognaese recipes:\n",
      "1 bowl of gluten\n",
      "\n",
      "Original secret: 1010011010110010\n",
      "Recovered secret: 0000000000110011\n"
     ]
    }
   ],
   "source": [
    "# Final end-to-end test\n",
    "\n",
    "carrier = \"Give me a recipe for pasta bolognese\"\n",
    "secret = generate_secret().to(device)\n",
    "\n",
    "stego_text = encode(carrier, secret)\n",
    "recovered_secret = decode(stego_text)\n",
    "\n",
    "print(\"Stego text:\")\n",
    "print(stego_text)\n",
    "print()\n",
    "print(\"Original secret:\", bits_to_str(secret[0]))\n",
    "print(\"Recovered secret:\", bits_to_str(recovered_secret))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stega",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
